{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be5d892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tcn import TCN\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd40d583",
   "metadata": {},
   "source": [
    "## Testing by discarding Nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4366441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(healthy, patho):\n",
    "    # Ensure both dataframes have the same columns\n",
    "    assert all(healthy.columns == patho.columns), \"DataFrames must have the same columns\"\n",
    "\n",
    "    \n",
    "    # Calculate the difference\n",
    "    diff = healthy - patho\n",
    "    diff = diff.dropna(axis=1)\n",
    "\n",
    "    return abs(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f56b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# healthy_data = pd.read_csv('C:\\DumbStuff\\epf study\\Meta-Elasto\\data\\Resultados\\Elastome_0001_Healthy_angle_1.csv')\n",
    "# patho_data = pd.read_csv('C:\\DumbStuff\\epf study\\Meta-Elasto\\data\\Resultados\\Elastome_0001_Patho_angle_1.csv')\n",
    "\n",
    "# diff_data = difference(healthy_data, patho_data)\n",
    "# diff_data.to_csv('diff.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc5ca896",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'C:\\\\DumbStuff\\\\epf study\\\\Meta-Elasto\\\\data\\\\Resultados'\n",
    "\n",
    "for i in range(1, 29):\n",
    "    try:\n",
    "        healthy=pd.read_csv(f'{dir}\\\\Elastome_{i:04}_Healthy_angle_1.csv')\n",
    "        patho=pd.read_csv(f'{dir}\\\\Elastome_{i:04}_Patho_angle_1.csv')\n",
    "        diff = difference(healthy, patho)\n",
    "        diff.to_csv(f'csvs\\\\diff_{i:04}.csv', index=False)\n",
    "    except FileNotFoundError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2df4d2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19,)\n"
     ]
    }
   ],
   "source": [
    "labels_csv = pd.read_excel('C:\\\\DumbStuff\\\\epf study\\\\Meta-Elasto\\\\data\\\\real0list.xlsx')\n",
    "\n",
    "y=labels_csv['Score (type)'].values\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40c0ab1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 2000, 7)\n"
     ]
    }
   ],
   "source": [
    "all_patient_dataset = []\n",
    "dir2 = 'C:\\\\DumbStuff\\\\epf study\\\\Meta-Elasto\\\\separate\\\\csvs'\n",
    "all_patient_dataset = []\n",
    "for filename in os.listdir(dir2):\n",
    "    filepath = os.path.join(dir2, filename)\n",
    "    data = pd.read_csv(filepath)\n",
    "    all_patient_dataset.append(data.values)\n",
    "\n",
    "X = np.array(all_patient_dataset)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "563bca1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- After splitting ---\n",
      "X_train shape: (15, 2000, 7)\n",
      "y_train shape: (15,)\n",
      "X_test shape: (4, 2000, 7)\n",
      "y_test shape: (4,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\n--- After splitting ---\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e094a836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ tcn_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TCN</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">22,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ tcn_2 (\u001b[38;5;33mTCN\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m22,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m198\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,886</span> (89.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,886\u001b[0m (89.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,886</span> (89.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,886\u001b[0m (89.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.2000 - loss: 3.0259 - val_accuracy: 0.0000e+00 - val_loss: 1.8503\n",
      "Epoch 2/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.1333 - loss: 3.0781 - val_accuracy: 0.0000e+00 - val_loss: 1.8291\n",
      "Epoch 3/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.1333 - loss: 2.1885 - val_accuracy: 0.0000e+00 - val_loss: 1.8204\n",
      "Epoch 4/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.2000 - loss: 1.9301 - val_accuracy: 0.0000e+00 - val_loss: 1.8148\n",
      "Epoch 5/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.0667 - loss: 2.3846 - val_accuracy: 0.2500 - val_loss: 1.8048\n",
      "Epoch 6/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.2000 - loss: 1.9205 - val_accuracy: 0.5000 - val_loss: 1.7955\n",
      "Epoch 7/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.2000 - loss: 2.4303 - val_accuracy: 0.5000 - val_loss: 1.7881\n",
      "Epoch 8/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.3333 - loss: 2.1444 - val_accuracy: 0.5000 - val_loss: 1.7841\n",
      "Epoch 9/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.2667 - loss: 1.7679 - val_accuracy: 0.5000 - val_loss: 1.7805\n",
      "Epoch 10/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4000 - loss: 1.7488 - val_accuracy: 0.5000 - val_loss: 1.7750\n",
      "Epoch 11/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 2.0397 - val_accuracy: 0.5000 - val_loss: 1.7687\n",
      "Epoch 12/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.3333 - loss: 1.7875 - val_accuracy: 0.5000 - val_loss: 1.7633\n",
      "Epoch 13/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.2667 - loss: 1.8044 - val_accuracy: 0.5000 - val_loss: 1.7582\n",
      "Epoch 14/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.6492 - val_accuracy: 0.5000 - val_loss: 1.7527\n",
      "Epoch 15/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4000 - loss: 1.7056 - val_accuracy: 0.5000 - val_loss: 1.7460\n",
      "Epoch 16/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4000 - loss: 1.6654 - val_accuracy: 0.5000 - val_loss: 1.7401\n",
      "Epoch 17/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4667 - loss: 1.6486 - val_accuracy: 0.5000 - val_loss: 1.7338\n",
      "Epoch 18/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4667 - loss: 1.6461 - val_accuracy: 0.5000 - val_loss: 1.7276\n",
      "Epoch 19/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.3333 - loss: 1.7058 - val_accuracy: 0.5000 - val_loss: 1.7208\n",
      "Epoch 20/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5333 - loss: 1.6288 - val_accuracy: 0.5000 - val_loss: 1.7141\n",
      "Epoch 21/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.4000 - loss: 1.6316 - val_accuracy: 0.5000 - val_loss: 1.7064\n",
      "Epoch 22/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.4667 - loss: 1.5868 - val_accuracy: 0.5000 - val_loss: 1.6986\n",
      "Epoch 23/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.4667 - loss: 1.5953 - val_accuracy: 0.5000 - val_loss: 1.6909\n",
      "Epoch 24/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.5868 - val_accuracy: 0.5000 - val_loss: 1.6830\n",
      "Epoch 25/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4000 - loss: 1.6366 - val_accuracy: 0.5000 - val_loss: 1.6753\n",
      "Epoch 26/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.6872 - val_accuracy: 0.5000 - val_loss: 1.6671\n",
      "Epoch 27/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4000 - loss: 1.5535 - val_accuracy: 0.5000 - val_loss: 1.6590\n",
      "Epoch 28/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4000 - loss: 1.5624 - val_accuracy: 0.5000 - val_loss: 1.6504\n",
      "Epoch 29/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4667 - loss: 1.5343 - val_accuracy: 0.5000 - val_loss: 1.6422\n",
      "Epoch 30/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.5548 - val_accuracy: 0.5000 - val_loss: 1.6349\n",
      "Epoch 31/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.5335 - val_accuracy: 0.5000 - val_loss: 1.6287\n",
      "Epoch 32/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.5130 - val_accuracy: 0.5000 - val_loss: 1.6224\n",
      "Epoch 33/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.5338 - val_accuracy: 0.5000 - val_loss: 1.6164\n",
      "Epoch 34/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4667 - loss: 1.5832 - val_accuracy: 0.5000 - val_loss: 1.6105\n",
      "Epoch 35/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.4810 - val_accuracy: 0.5000 - val_loss: 1.6040\n",
      "Epoch 36/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.4000 - loss: 1.6320 - val_accuracy: 0.5000 - val_loss: 1.5961\n",
      "Epoch 37/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.4802 - val_accuracy: 0.5000 - val_loss: 1.5885\n",
      "Epoch 38/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4667 - loss: 1.4751 - val_accuracy: 0.5000 - val_loss: 1.5811\n",
      "Epoch 39/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.4743 - val_accuracy: 0.5000 - val_loss: 1.5739\n",
      "Epoch 40/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.4667 - loss: 1.4791 - val_accuracy: 0.5000 - val_loss: 1.5661\n",
      "Epoch 41/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.5129 - val_accuracy: 0.5000 - val_loss: 1.5592\n",
      "Epoch 42/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.5272 - val_accuracy: 0.5000 - val_loss: 1.5519\n",
      "Epoch 43/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4000 - loss: 1.5162 - val_accuracy: 0.5000 - val_loss: 1.5440\n",
      "Epoch 44/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.4774 - val_accuracy: 0.5000 - val_loss: 1.5379\n",
      "Epoch 45/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.4667 - loss: 1.5062 - val_accuracy: 0.5000 - val_loss: 1.5334\n",
      "Epoch 46/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4667 - loss: 1.4114 - val_accuracy: 0.5000 - val_loss: 1.5276\n",
      "Epoch 47/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4667 - loss: 1.4703 - val_accuracy: 0.5000 - val_loss: 1.5208\n",
      "Epoch 48/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4667 - loss: 1.4033 - val_accuracy: 0.5000 - val_loss: 1.5133\n",
      "Epoch 49/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.4612 - val_accuracy: 0.5000 - val_loss: 1.5054\n",
      "Epoch 50/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.4432 - val_accuracy: 0.5000 - val_loss: 1.4981\n",
      "Epoch 51/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.4207 - val_accuracy: 0.5000 - val_loss: 1.4907\n",
      "Epoch 52/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.3709 - val_accuracy: 0.5000 - val_loss: 1.4834\n",
      "Epoch 53/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.3853 - val_accuracy: 0.5000 - val_loss: 1.4763\n",
      "Epoch 54/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.4667 - loss: 1.3145 - val_accuracy: 0.5000 - val_loss: 1.4692\n",
      "Epoch 55/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.5309 - val_accuracy: 0.5000 - val_loss: 1.4640\n",
      "Epoch 56/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.4667 - loss: 1.3886 - val_accuracy: 0.5000 - val_loss: 1.4595\n",
      "Epoch 57/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4667 - loss: 1.4889 - val_accuracy: 0.5000 - val_loss: 1.4563\n",
      "Epoch 58/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.3929 - val_accuracy: 0.5000 - val_loss: 1.4528\n",
      "Epoch 59/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.4536 - val_accuracy: 0.5000 - val_loss: 1.4475\n",
      "Epoch 60/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.3265 - val_accuracy: 0.5000 - val_loss: 1.4408\n",
      "Epoch 61/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.3306 - val_accuracy: 0.5000 - val_loss: 1.4331\n",
      "Epoch 62/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.3117 - val_accuracy: 0.5000 - val_loss: 1.4255\n",
      "Epoch 63/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.4667 - loss: 1.3549 - val_accuracy: 0.5000 - val_loss: 1.4165\n",
      "Epoch 64/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.4667 - loss: 1.3751 - val_accuracy: 0.5000 - val_loss: 1.4092\n",
      "Epoch 65/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.3524 - val_accuracy: 0.5000 - val_loss: 1.4027\n",
      "Epoch 66/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.2456 - val_accuracy: 0.5000 - val_loss: 1.3966\n",
      "Epoch 67/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.3990 - val_accuracy: 0.5000 - val_loss: 1.3926\n",
      "Epoch 68/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.1909 - val_accuracy: 0.5000 - val_loss: 1.3872\n",
      "Epoch 69/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.3207 - val_accuracy: 0.5000 - val_loss: 1.3800\n",
      "Epoch 70/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.3847 - val_accuracy: 0.5000 - val_loss: 1.3736\n",
      "Epoch 71/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4667 - loss: 1.1862 - val_accuracy: 0.5000 - val_loss: 1.3670\n",
      "Epoch 72/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5333 - loss: 1.3801 - val_accuracy: 0.5000 - val_loss: 1.3627\n",
      "Epoch 73/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.3209 - val_accuracy: 0.5000 - val_loss: 1.3579\n",
      "Epoch 74/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5333 - loss: 1.2343 - val_accuracy: 0.5000 - val_loss: 1.3528\n",
      "Epoch 75/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.4130 - val_accuracy: 0.5000 - val_loss: 1.3477\n",
      "Epoch 76/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4000 - loss: 1.2331 - val_accuracy: 0.5000 - val_loss: 1.3445\n",
      "Epoch 77/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.2926 - val_accuracy: 0.5000 - val_loss: 1.3426\n",
      "Epoch 78/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.3427 - val_accuracy: 0.5000 - val_loss: 1.3426\n",
      "Epoch 79/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5333 - loss: 1.2228 - val_accuracy: 0.5000 - val_loss: 1.3424\n",
      "Epoch 80/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4667 - loss: 1.2932 - val_accuracy: 0.5000 - val_loss: 1.3438\n",
      "Epoch 81/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.3686 - val_accuracy: 0.5000 - val_loss: 1.3458\n",
      "Epoch 82/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.2145 - val_accuracy: 0.5000 - val_loss: 1.3466\n",
      "Epoch 83/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.4667 - loss: 1.3816 - val_accuracy: 0.5000 - val_loss: 1.3482\n",
      "Epoch 84/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.3474 - val_accuracy: 0.5000 - val_loss: 1.3498\n",
      "Epoch 85/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.2361 - val_accuracy: 0.5000 - val_loss: 1.3500\n",
      "Epoch 86/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.3383 - val_accuracy: 0.5000 - val_loss: 1.3494\n",
      "Epoch 87/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.4667 - loss: 1.3636 - val_accuracy: 0.5000 - val_loss: 1.3487\n",
      "Epoch 88/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.2017 - val_accuracy: 0.5000 - val_loss: 1.3440\n",
      "Epoch 89/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.4667 - loss: 1.1950 - val_accuracy: 0.5000 - val_loss: 1.3424\n",
      "Epoch 90/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4667 - loss: 1.2267 - val_accuracy: 0.5000 - val_loss: 1.3407\n",
      "Epoch 91/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5333 - loss: 1.2837 - val_accuracy: 0.5000 - val_loss: 1.3407\n",
      "Epoch 92/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.4667 - loss: 1.2329 - val_accuracy: 0.5000 - val_loss: 1.3415\n",
      "Epoch 93/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5333 - loss: 1.3364 - val_accuracy: 0.5000 - val_loss: 1.3428\n",
      "Epoch 94/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4000 - loss: 1.2805 - val_accuracy: 0.5000 - val_loss: 1.3444\n",
      "Epoch 95/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.2496 - val_accuracy: 0.5000 - val_loss: 1.3452\n",
      "Epoch 96/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5333 - loss: 1.1761 - val_accuracy: 0.5000 - val_loss: 1.3444\n",
      "Epoch 97/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.4667 - loss: 1.2739 - val_accuracy: 0.5000 - val_loss: 1.3424\n",
      "Epoch 98/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.5333 - loss: 1.0035 - val_accuracy: 0.5000 - val_loss: 1.3402\n",
      "Epoch 99/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.4667 - loss: 1.2818 - val_accuracy: 0.5000 - val_loss: 1.3388\n",
      "Epoch 100/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5333 - loss: 1.2433 - val_accuracy: 0.5000 - val_loss: 1.3390\n",
      "Epoch 101/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.4667 - loss: 1.3756 - val_accuracy: 0.5000 - val_loss: 1.3423\n",
      "Epoch 102/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5333 - loss: 1.2779 - val_accuracy: 0.5000 - val_loss: 1.3438\n",
      "Epoch 103/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.4119 - val_accuracy: 0.5000 - val_loss: 1.3479\n",
      "Epoch 104/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.1802 - val_accuracy: 0.5000 - val_loss: 1.3505\n",
      "Epoch 105/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6000 - loss: 1.1993 - val_accuracy: 0.5000 - val_loss: 1.3530\n",
      "Epoch 106/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.4667 - loss: 1.1676 - val_accuracy: 0.5000 - val_loss: 1.3536\n",
      "Epoch 107/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5333 - loss: 1.2906 - val_accuracy: 0.5000 - val_loss: 1.3527\n",
      "Epoch 108/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5333 - loss: 1.2561 - val_accuracy: 0.5000 - val_loss: 1.3503\n",
      "Epoch 109/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5333 - loss: 1.2319 - val_accuracy: 0.5000 - val_loss: 1.3467\n",
      "Epoch 110/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5333 - loss: 1.0997 - val_accuracy: 0.5000 - val_loss: 1.3432\n",
      "Epoch 111/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.4667 - loss: 1.3697 - val_accuracy: 0.5000 - val_loss: 1.3418\n",
      "Epoch 112/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.4667 - loss: 1.2621 - val_accuracy: 0.5000 - val_loss: 1.3394\n",
      "Epoch 113/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4667 - loss: 1.2254 - val_accuracy: 0.5000 - val_loss: 1.3391\n",
      "Epoch 114/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4667 - loss: 1.1196 - val_accuracy: 0.5000 - val_loss: 1.3366\n",
      "Epoch 115/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5333 - loss: 1.0699 - val_accuracy: 0.5000 - val_loss: 1.3320\n",
      "Epoch 116/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.4667 - loss: 1.3802 - val_accuracy: 0.5000 - val_loss: 1.3313\n",
      "Epoch 117/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5333 - loss: 1.2454 - val_accuracy: 0.5000 - val_loss: 1.3307\n",
      "Epoch 118/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4000 - loss: 1.3109 - val_accuracy: 0.5000 - val_loss: 1.3305\n",
      "Epoch 119/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4667 - loss: 1.0958 - val_accuracy: 0.5000 - val_loss: 1.3317\n",
      "Epoch 120/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5333 - loss: 1.1507 - val_accuracy: 0.5000 - val_loss: 1.3315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x256ed1aa350>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# One-hot encode the integer labels\n",
    "y_train_categorical = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_categorical = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# BASELINE MODEL\n",
    "model_baseline = Sequential([\n",
    "    Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    TCN(nb_filters=32, kernel_size=3, dilations=[1, 2, 4, 8], dropout_rate=0.2),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model_baseline.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_baseline.summary()\n",
    "\n",
    "# Train the model with the one-hot encoded labels\n",
    "model_baseline.fit(\n",
    "    X_train, \n",
    "    y_train_categorical, \n",
    "    validation_data=(X_test, y_test_categorical), \n",
    "    epochs=120, \n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbc9243",
   "metadata": {},
   "source": [
    "## Testing by filling in Nan Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4013813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(df):\n",
    "    \"\"\"\n",
    "    Fills NaN values in a DataFrame using linear interpolation.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame that may contain NaN values.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with all NaN values filled.\n",
    "    \"\"\"\n",
    "    # interpolate() fills missing values.\n",
    "    # - method='linear' treats values as equally spaced, which is good for time series.\n",
    "    # - limit_direction='both' fills NaNs at the beginning and end of each column.\n",
    "    df_filled = df.interpolate(method='linear', limit_direction='both')\n",
    "    \n",
    "    return df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce5b4801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(healthy, patho):\n",
    "\n",
    "    if healthy.isnull().values.any():\n",
    "        fill_missing_values(healthy)\n",
    "    if patho.isnull().values.any():\n",
    "        fill_missing_values(patho)\n",
    "\n",
    "    # Ensure both dataframes have the same columns\n",
    "    assert all(healthy.columns == patho.columns), \"DataFrames must have the same columns\"\n",
    "    \n",
    "    # Calculate the difference\n",
    "    diff = healthy - patho\n",
    "\n",
    "    return abs(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3929d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'C:\\\\DumbStuff\\\\epf study\\\\Meta-Elasto\\\\data\\\\Resultados'\n",
    "\n",
    "for i in range(1, 29):\n",
    "    try:\n",
    "        healthy=pd.read_csv(f'{dir}\\\\Elastome_{i:04}_Healthy_angle_1.csv')\n",
    "        patho=pd.read_csv(f'{dir}\\\\Elastome_{i:04}_Patho_angle_1.csv')\n",
    "        diff = difference(healthy, patho)\n",
    "        diff.to_csv(f'csvs-nan\\\\diff_{i:04}.csv', index=False)\n",
    "    except FileNotFoundError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cedd18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19,)\n"
     ]
    }
   ],
   "source": [
    "labels_csv = pd.read_excel('C:\\\\DumbStuff\\\\epf study\\\\Meta-Elasto\\\\data\\\\real0list.xlsx')\n",
    "\n",
    "y=labels_csv['Score (type)'].values\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c23b876c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 2000, 18)\n"
     ]
    }
   ],
   "source": [
    "all_patient_dataset = []\n",
    "dir2 = 'C:\\\\DumbStuff\\\\epf study\\\\Meta-Elasto\\\\separate\\\\csvs-nan'\n",
    "all_patient_dataset = []\n",
    "for filename in os.listdir(dir2):\n",
    "    filepath = os.path.join(dir2, filename)\n",
    "    data = pd.read_csv(filepath)\n",
    "    all_patient_dataset.append(data.values)\n",
    "\n",
    "X = np.array(all_patient_dataset)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "023c427b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- After splitting ---\n",
      "X_train shape: (15, 2000, 18)\n",
      "y_train shape: (15,)\n",
      "X_test shape: (4, 2000, 18)\n",
      "y_test shape: (4,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\n--- After splitting ---\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6e3c83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ameyd\\.conda\\envs\\epf\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ tcn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TCN</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ tcn (\u001b[38;5;33mTCN\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m24,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m198\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,294</span> (94.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,294\u001b[0m (94.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,294</span> (94.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,294\u001b[0m (94.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 2/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 3/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 4/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 5/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 6/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 7/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 8/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 9/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 10/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 11/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 12/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 13/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 14/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 15/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 16/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 17/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 18/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 19/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 20/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 21/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 22/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 23/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 24/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 25/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 26/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 27/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 28/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 29/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 30/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 31/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 32/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 33/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 34/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 35/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 36/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 37/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 38/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 39/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 40/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 41/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 42/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 43/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 44/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 45/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 46/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 47/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 48/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 49/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 50/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 51/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 52/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 53/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 54/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 55/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 56/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 57/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 58/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 59/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 60/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 61/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 62/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 63/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 64/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 65/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 66/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 67/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 68/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 69/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 70/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 71/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 72/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 73/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 74/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 75/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 76/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 77/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 78/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 79/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 80/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 81/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 82/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 83/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 84/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 85/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 86/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 87/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 88/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 89/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 90/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 91/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 92/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 93/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 94/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 95/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 96/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 97/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 98/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 99/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 100/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 101/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 102/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 103/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 104/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 105/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 106/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 107/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 108/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 109/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 110/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 111/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 112/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 113/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 114/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 115/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 116/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 117/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 118/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 119/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n",
      "Epoch 120/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: nan - val_accuracy: 0.2500 - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x239e21796a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# One-hot encode the integer labels\n",
    "y_train_categorical = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_categorical = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# BASELINE MODEL\n",
    "model_baseline = Sequential([\n",
    "    Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    TCN(nb_filters=32, kernel_size=3, dilations=[1, 2, 4, 8], dropout_rate=0.2),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model_baseline.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_baseline.summary()\n",
    "\n",
    "# Train the model with the one-hot encoded labels\n",
    "model_baseline.fit(\n",
    "    X_train, \n",
    "    y_train_categorical, \n",
    "    validation_data=(X_test, y_test_categorical), \n",
    "    epochs=120, \n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92452429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
